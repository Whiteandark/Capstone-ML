{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning using HyperDrive\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import choice"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1617837958445
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "experiment_name = 'Capstone-cancer-experiment-hyperdrive'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1617837962776
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "compute_cluster_name = 'cluster-capstone'\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name = compute_cluster_name)\n",
        "    print('Found the compute cluster')\n",
        "\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D3_V2\", max_nodes=4)\n",
        "    compute_target = ComputeTarget.create(ws, compute_cluster_name, compute_config)\n",
        "    compute_target.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1617837985766
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperdrive Configuration\n",
        "\n"
      ],
      "metadata": {
        "gather": {
          "logged": 1598531923519
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.parameter_expressions import choice, uniform\n",
        "from azureml.core import Environment\n",
        "import os\n",
        "from azureml.core.script_run_config import ScriptRunConfig\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.parameter_expressions import choice\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "if \"training\" not in os.listdir():\n",
        "    os.mkdir(\"./training\")\n",
        "shutil.copy('./train.py','./training')\n",
        "\n",
        "#TODO: Create the different params that you will be using during training\n",
        "\n",
        "param_sampling = RandomParameterSampling(\n",
        "    {\n",
        "        '--C' : choice(0.001,0.01,0.1,1,10,20,50,100,200,500,1000),\n",
        "        '--max_iter': choice(50,100,200,300)\n",
        "    }\n",
        ")\n",
        "\n",
        "# Specify a Policy\n",
        "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
        "\n",
        "# configure and submit your training run\n",
        "src = ScriptRunConfig(source_directory=\"./training\",\n",
        "                      script='train.py',\n",
        "                      compute_target=compute_target)\n",
        "\n",
        "#Submit job : Run your experiment by submitting your ScriptRunConfig object. Note that this call is asynchronous.\n",
        "run = experiment.submit(src)\n",
        "\n",
        "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
        "                                     policy=policy,\n",
        "                                     hyperparameter_sampling=param_sampling, \n",
        "                                     primary_metric_name='Accuracy',\n",
        "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                                     max_total_runs=8,\n",
        "                                     max_concurrent_runs=4)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1617838032921
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Submit your experiment\n",
        "hyperdrive_run = experiment.submit(hyperdrive_config)\n",
        "\n",
        "# Monitor HyperDrive runs You can monitor the progress of the runs with the following Jupyter widget\n",
        "# RunDetails(hyperdrive_run).show()\n",
        "\n",
        "hyperdrive_run.wait_for_completion(show_output=True)\n",
        "\n",
        "assert(hyperdrive_run.get_status() == \"Completed\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RunId: HD_310f6504-398b-4c81-883f-a920039d3f57\n",
            "Web View: https://ml.azure.com/experiments/Capstone-cancer-experiment-hyperdrive/runs/HD_310f6504-398b-4c81-883f-a920039d3f57?wsid=/subscriptions/08429d2c-c480-438d-b360-41b472ce37a7/resourcegroups/ml/workspaces/udacity-projects\n",
            "\n",
            "Streaming azureml-logs/hyperdrive.txt\n",
            "=====================================\n",
            "\n",
            "\"<START>[2021-04-07T23:29:33.230079][API][INFO]Experiment created<END>\\n\"\"<START>[2021-04-07T23:29:33.984863][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space<END>\\n\"\"<START>[2021-04-07T23:29:34.333154][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.<END>\\n\"<START>[2021-04-07T23:29:34.9711277Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.<END>\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1617724196626
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {
        "gather": {
          "logged": 1598544898497
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(hyperDrive_run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1617046107596
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_run = hyperDrive_run.get_best_run_by_primary_metric()\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "\n",
        "print('Best Run Id: ', best_run.id)\n",
        "print('\\n Accuracy:', best_run_metrics['Accuracy'])\n",
        "print('\\n Regularization Strength:',best_run_metrics['Regularization Strength:'])\n",
        "print('\\n Max Iterations:',best_run_metrics['Max iterations:'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1598546650307
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code below registers the best model with the information of Metrics\n",
        "model = best_run.register_model(model_name='HyperDrive_HighAccuracy', model_path='outputs/', \n",
        "                                properties={'Accuracy': best_run_metrics['Accuracy'],\n",
        "                                            'Regularization Strength': best_run_metrics['Regularization Strength:'],\n",
        "                                           'Max Iterations': best_run_metrics['Max iterations:']})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1598546657829
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}